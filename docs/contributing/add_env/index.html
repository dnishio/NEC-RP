<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../../img/favicon.ico">
  <title>Adding a New Environment - Reinforcement Learning Coach</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../../css/highlight.css">
  <link href="../../extra.css" rel="stylesheet">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Adding a New Environment";
    var mkdocs_page_input_path = "contributing/add_env.md";
    var mkdocs_page_url = "/contributing/add_env/";
  </script>
  
  <script src="../../js/jquery-2.1.1.min.js"></script>
  <script src="../../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../../js/highlight.pack.js"></script> 
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href="../.." class="icon icon-home"> Reinforcement Learning Coach</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="../..">Home</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../usage/">Usage</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Design</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../design/features/">Features</a>
                </li>
                <li class="">
                    
    <a class="" href="../../design/control_flow/">Control Flow</a>
                </li>
                <li class="">
                    
    <a class="" href="../../design/network/">Network</a>
                </li>
                <li class="">
                    
    <a class="" href="../../design/filters/">Filters</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Algorithms</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/dqn/">DQN</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/double_dqn/">Double DQN</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/dueling_dqn/">Dueling DQN</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/categorical_dqn/">Categorical DQN</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/mmc/">Mixed Monte Carlo</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/pal/">Persistent Advantage Learning</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/nec/">Neural Episodic Control</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/bs_dqn/">Bootstrapped DQN</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/n_step/">N-Step Q Learning</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/value_optimization/naf/">Normalized Advantage Functions</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/policy_optimization/pg/">Policy Gradient</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/policy_optimization/ac/">Actor-Critic</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/policy_optimization/ddpg/">Deep Determinstic Policy Gradients</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/policy_optimization/ppo/">Proximal Policy Optimization</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/policy_optimization/cppo/">Clipped Proximal Policy Optimization</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/other/dfp/">Direct Future Prediction</a>
                </li>
                <li class="">
                    
    <a class="" href="../../algorithms/imitation/bc/">Behavioral Cloning</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../../dashboard/">Coach Dashboard</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Contributing</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../add_agent/">Adding a New Agent</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Adding a New Environment</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#using-the-openai-gym-api">Using the OpenAI Gym API</a></li>
    

    <li class="toctree-l3"><a href="#using-the-coach-api">Using the Coach API</a></li>
    

    </ul>
                </li>
    </ul>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../..">Reinforcement Learning Coach</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../..">Docs</a> &raquo;</li>
    
      
        
          <li>Contributing &raquo;</li>
        
      
    
    <li>Adding a New Environment</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <p>Adding a new environment to Coach is as easy as solving CartPole. </p>
<p>There are essentially two ways to integrate new environments to Coach:</p>
<h2 id="using-the-openai-gym-api">Using the OpenAI Gym API</h2>
<p>If your environment is already using the OpenAI Gym API, you are already good to go.
When selecting the environment parameters in the preset, use GymEnvironmentParameters(),
and pass the path to your environment source code using the level parameter.
You can specify additional parameters for your environment using the additional_simulator_parameters parameter.
Take for example the definition used in the Pendulum_HAC preset:</p>
<pre><code>    env_params = GymEnvironmentParameters()
    env_params.level = "rl_coach.environments.mujoco.pendulum_with_goals:PendulumWithGoals"
    env_params.additional_simulator_parameters = {"time_limit": 1000}
</code></pre>
<h2 id="using-the-coach-api">Using the Coach API</h2>
<p>There are a few simple steps to follow, and we will walk through them one by one.</p>
<ol>
<li>
<p>Create a new class for your environment, and inherit the Environment class.</p>
</li>
<li>
<p>Coach defines a simple API for implementing a new environment, which are defined in environment/environment.py.
    There are several functions to implement, but only some of them are mandatory.</p>
<p>Here are the important ones:</p>
<pre><code>    def _take_action(self, action_idx: ActionType) -&gt; None:
        """
        An environment dependent function that sends an action to the simulator.
        :param action_idx: the action to perform on the environment
        :return: None
        """

    def _update_state(self) -&gt; None:
        """
        Updates the state from the environment.
        Should update self.observation, self.reward, self.done, self.measurements and self.info
        :return: None
        """

    def _restart_environment_episode(self, force_environment_reset=False) -&gt; None:
        """
        Restarts the simulator episode
        :param force_environment_reset: Force the environment to reset even if the episode is not done yet.
        :return: None
        """

    def _render(self) -&gt; None:
        """
        Renders the environment using the native simulator renderer
        :return: None
        """

    def get_rendered_image(self) -&gt; np.ndarray:
        """
        Return a numpy array containing the image that will be rendered to the screen.
        This can be different from the observation. For example, mujoco's observation is a measurements vector.
        :return: numpy array containing the image that will be rendered to the screen
        """
</code></pre>
</li>
<li>
<p>Create a new parameters class for your environment, which inherits the EnvironmentParameters class.
    In the <strong>init</strong> of your class, define all the parameters you used in your Environment class.
    Additionally, fill the path property of the class with the path to your Environment class.
    For example, take a look at the EnvironmentParameters class used for Doom:</p>
<pre><code>    class DoomEnvironmentParameters(EnvironmentParameters):
    def __init__(self):
        super().__init__()
        self.default_input_filter = DoomInputFilter
        self.default_output_filter = DoomOutputFilter
        self.cameras = [DoomEnvironment.CameraTypes.OBSERVATION]

    @property
    def path(self):
        return 'rl_coach.environments.doom_environment:DoomEnvironment'
</code></pre>
</li>
<li>
<p>And that's it, you're done. Now just add a new preset with your newly created environment, and start training an agent on top of it.</p>
</li>
</ol>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="../add_agent/" class="btn btn-neutral" title="Adding a New Agent"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
      
        <span><a href="../add_agent/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
    </span>
</div>
    <script>var base_url = '../..';</script>
    <script src="../../js/theme.js"></script>
      <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
      <script src="../../search/require.js"></script>
      <script src="../../search/search.js"></script>

</body>
</html>
